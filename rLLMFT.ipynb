{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "ExOJWn0K6gFX",
        "eqJXuV2p_PW1",
        "rata_hgW7pLb",
        "DXncESoC60hW",
        "skV-VdEr7Fch",
        "bbOKl3tlXMjg",
        "JrIc8Zpd-txH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Foreword\n",
        "\n",
        "We welcome you to use rLLMFT, a sub-implementation of the PCRLLM research, to replicate the experiments in the paper *PCRLLM: Proof-Carrying Reasoning with Large Language Models under Stepwise Logical Constraints*. Since we don't have a powerful GPU, we can only present this as a Colab script. Below is an introduction to using this script:\n",
        "\n",
        "1) Data Generation: We will generate training data **for different LLMs** and test data for all models all at once.\n",
        "\n",
        "2) Each *cycle* involves fine-tuning and testing a specific LLM, generating a file for logging after testing. This cycle should be performed once for each LLM. However, since this is a Colab script, completely uninstalling a model while maintaining a session is somewhat complex. Therefore, we need you to repeatedly disconnect/connect to this script as you change the *model index* to **download test data**.\n",
        "\n",
        "3) Final Scoring: After completing the last cycle, you can use the grading box. You will need to upload the test data files for all previous models.\n",
        "\n",
        "Thank you for using this script! If you have any questions, feel free to send email to tuo90515@temple.edu."
      ],
      "metadata": {
        "id": "OPT558IEI9XO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config & Datagen"
      ],
      "metadata": {
        "id": "ExOJWn0K6gFX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FAuAwXl6Qab"
      },
      "outputs": [],
      "source": [
        "TOKENIZER_LENGTH = 800\n",
        "\n",
        "NUM_FINETUNE_DATA = 100\n",
        "NUM_FINETUNE_EPOCHS = 2\n",
        "\n",
        "# model_name = \"Qwen/Qwen2.5-0.5B\"\n",
        "model_name = \"Qwen/Qwen2.5-1.5B\"\n",
        "\n",
        "NUM_MODELS = 3\n",
        "\n",
        "USER_TAG = \"User:\"\n",
        "ASSISTANT_TAG = \"Assistant:\"\n",
        "\n",
        "seed = 39"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MoonWalker1997/rLLMFT.git\n",
        "!python ./rLLMFT/data_gen.py --num_data {NUM_FINETUNE_DATA} --num_models {NUM_MODELS} --random_seed {seed}"
      ],
      "metadata": {
        "id": "oowLwkRi6knj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import csv\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import transformers\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments)"
      ],
      "metadata": {
        "id": "67ERSgVF-8Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Util"
      ],
      "metadata": {
        "id": "G9NG3QnQB1zO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_full_text(row):\n",
        "    intro = row[\"Introduction\"].strip()\n",
        "    premise = row[\"Premise\"].strip()\n",
        "    question = row[\"Question\"].strip()\n",
        "    answer = row[\"Answer\"].strip()\n",
        "    return f\"{intro}\\n{USER_TAG} {premise} {question}\\n{ASSISTANT_TAG} {answer}{tokenizer.eos_token}\"\n",
        "\n",
        "\n",
        "def preprocess(row):\n",
        "    full_text = get_full_text(row)\n",
        "    asst_idx = full_text.rfind(ASSISTANT_TAG)\n",
        "    enc = tokenizer(full_text, truncation=True, max_length=TOKENIZER_LENGTH)\n",
        "    input_ids = enc[\"input_ids\"]\n",
        "\n",
        "    prefix_text = full_text[:asst_idx]\n",
        "    prefix_ids = tokenizer(prefix_text, truncation=True, max_length=TOKENIZER_LENGTH)[\"input_ids\"]\n",
        "    mask_start = len(prefix_ids)\n",
        "\n",
        "    labels = [-100] * mask_start + input_ids[mask_start:]\n",
        "    enc[\"labels\"] = labels\n",
        "    return enc\n",
        "\n",
        "def get_full_text_test(row):\n",
        "    intro = row[\"Introduction\"].strip()\n",
        "    premise = row[\"Premise\"].strip()\n",
        "    question = row[\"Question\"].strip()\n",
        "    return f\"{intro}\\n{USER_TAG} {premise} {question}\\n{ASSISTANT_TAG}\"\n",
        "\n",
        "def preprocess_for_generate(row):\n",
        "    full_text = get_full_text_test(row)\n",
        "    return tokenizer(\n",
        "        full_text,\n",
        "        truncation=True,\n",
        "        max_length=TOKENIZER_LENGTH,)"
      ],
      "metadata": {
        "id": "RLcky2_TB3RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cycle"
      ],
      "metadata": {
        "id": "eqJXuV2p_PW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_INDEX = 2"
      ],
      "metadata": {
        "id": "XCrhfIoV_W5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full-Finetune"
      ],
      "metadata": {
        "id": "rata_hgW7pLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data and Model"
      ],
      "metadata": {
        "id": "DXncESoC60hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.model_max_length = TOKENIZER_LENGTH\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "df = pd.read_csv(f\"./data/data_table_{MODEL_INDEX}_{NUM_MODELS}.csv\",\n",
        "                 quotechar='\"',\n",
        "                 doublequote=True)\n",
        "dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "h_WyGraS61L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "skV-VdEr7Fch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(\n",
        "    preprocess,\n",
        "    batched=False,\n",
        "    remove_columns=dataset.column_names)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finetuned_model\",\n",
        "    per_device_train_batch_size=1,\n",
        "    num_train_epochs=NUM_FINETUNE_EPOCHS,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\",\n",
        "    bf16=True,\n",
        "    gradient_accumulation_steps=4,\n",
        "    report_to=[])\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset)\n",
        "\n",
        "print(\"Start...\")\n",
        "trainer.train()\n",
        "print(\"Finish\")"
      ],
      "metadata": {
        "id": "kwSu08-aHccD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "bbOKl3tlXMjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"./data/data_table_test.csv\",\n",
        "                      quotechar='\"',\n",
        "                      doublequote=True)\n",
        "\n",
        "dataset_test = Dataset.from_pandas(df_test)\n",
        "\n",
        "tokenized_test = dataset_test.map(\n",
        "    preprocess_for_generate,\n",
        "    batched=False,\n",
        "    remove_columns=dataset_test.column_names)\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    tokenized_test,\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    collate_fn=lambda batch: {\n",
        "        \"input_ids\": torch.nn.utils.rnn.pad_sequence(\n",
        "            [torch.tensor(x[\"input_ids\"]) for x in batch],\n",
        "            batch_first=True,\n",
        "            padding_value=tokenizer.pad_token_id\n",
        "        ),\n",
        "        \"attention_mask\": torch.nn.utils.rnn.pad_sequence(\n",
        "            [torch.tensor(x[\"attention_mask\"]) for x in batch],\n",
        "            batch_first=True,\n",
        "            padding_value=0\n",
        "        )\n",
        "    })\n",
        "\n",
        "model.eval()\n",
        "model.to(\"cuda\")\n",
        "\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "outputs = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm.tqdm(dataloader):\n",
        "        batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
        "        generated = model.generate(\n",
        "            **batch,\n",
        "            max_new_tokens=TOKENIZER_LENGTH - batch[\"input_ids\"].shape[1],\n",
        "            num_beams=1,\n",
        "            do_sample=False\n",
        "        )\n",
        "        texts = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
        "        outputs.extend(texts)\n",
        "\n",
        "tmp = []\n",
        "for i in range(len(dataset_test)):\n",
        "    tmp.append([get_full_text(dataset_test[i]), outputs[i]])\n",
        "\n",
        "with open(f\"./test_record/test_record_{MODEL_INDEX}_{NUM_MODELS}.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
        "    writer.writerow([\"Label\", \"Output\"])\n",
        "    for row in tmp:\n",
        "        writer.writerow(row)"
      ],
      "metadata": {
        "id": "POjjHJnD8BYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grading"
      ],
      "metadata": {
        "id": "JrIc8Zpd-txH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import os\n",
        "\n",
        "for old_name in uploaded.keys():\n",
        "    new_name = old_name.split(\"-\")[0] + \".csv\"\n",
        "    os.rename(old_name, new_name)\n",
        "\n",
        "for i in range(NUM_MODELS):\n",
        "    try:\n",
        "        shutil.move(f\"./test_record_{i}_{NUM_MODELS}.csv\", f\"./test_record/test_record_{i}_{NUM_MODELS}.csv\")\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "!python ./rLLMFT/grading.py"
      ],
      "metadata": {
        "id": "bjX-eyN_-vn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}